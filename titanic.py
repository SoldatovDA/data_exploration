# -*- coding: utf-8 -*-
"""Titanic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18X7qDWXbAo9CWgTbPyzbSSDwv_fRpfGf
"""

! pip install kaggle
! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json
! kaggle competitions download titanic

import zipfile
z = zipfile.ZipFile('titanic.zip', 'r')

z.printdir()

z.extractall()

import pandas as pd
import numpy as np
gender_submission = pd.read_csv('gender_submission.csv')
test = pd.read_csv('test.csv')
train = pd.read_csv('train.csv')

data = pd.concat([train, test])

data.info()

data.head()

data.describe(include='O')

data.isnull().sum()

data[['Pclass', 'Survived']].groupby('Pclass').mean()

data['Embarked'] = data['Embarked'].fillna('S')
data[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean()

data[['Sex', 'Survived']].groupby(['Sex'],).mean().sort_values(by='Survived', ascending=False)

data['FamilySize'] = data['SibSp'] + data['Parch']
data[['FamilySize', 'Survived']].groupby(['FamilySize'],).mean().sort_values(by='FamilySize', ascending=False)

data['Alone'] = data['FamilySize'] == 0
data[['Alone', 'Survived']].groupby(['Alone'],).mean().sort_values(by='Alone', ascending=False)

data['Fare'] = data['Fare'].fillna(train['Fare'].median())
data['CategoricalFare'] = pd.qcut(train['Fare'], 4, precision=0)
data[["CategoricalFare", "Survived"]].groupby(['CategoricalFare'],).mean().sort_values(by='CategoricalFare', ascending=False)

age_mean = data['Age'].mean()
age_std = data['Age'].std()
null_values_count = data['Age'].isnull().count() 
age_null_random_list = np.random.randint(age_mean - age_std, age_mean + age_std, size=null_values_count)


data['Age'][np.isnan(data['Age'])] = age_null_random_list
data['CategoricalAge'] = pd.cut(train['Age'], 5, precision=0)
data[["CategoricalAge", "Survived"]].groupby(['CategoricalAge'],).mean().sort_values(by='CategoricalAge', ascending=False)

def rightValue(interval):
  return interval.right

data['CategoricalAge'] = data['CategoricalAge'].apply(rightValue)
data['CategoricalFare'] = data['CategoricalFare'].apply(rightValue)
data.head()

drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp',\
                 'Parch', 'FamilySize', 'Age', ]
data = data.drop(drop_elements, axis = 1)

data.head()

from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
data['CategoricalFare'] = encoder.fit_transform(data['CategoricalFare'])
data['CategoricalAge'] = encoder.fit_transform(data['CategoricalAge'])
data['Alone'] = encoder.fit_transform(data['Alone'])
data.head()

import pandas as pd
import numpy as np
from sklearn.preprocessing import OneHotEncoder

enc = OneHotEncoder(handle_unknown='ignore')
# passing bridge-types-cat column (label encoded values of bridge_types)

enc_df = pd.DataFrame(enc.fit_transform(data[['Embarked', 'Sex']]).toarray())
# merge with main df bridge_df on key values

data = data.join(enc_df)
data = data.drop(['Embarked', 'Sex'], axis = 1)
data.reset_index()

data.head()

data.Alone = encoder.fit_transform(data.Alone)

data.head()

data.info()

data.drop(columns = ['Fare'])
data = data[data['Survived'].notna()]
data.info()

y = data['Survived'] 
X = data.drop(columns=['Survived'])

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score



classifiers = [
    KNeighborsClassifier(5),
    SVC(probability=True, kernel='rbf'),
    DecisionTreeClassifier(),
    RandomForestClassifier(),
    GaussianNB(),
    LogisticRegression(),
]

log_cols = ["Classifier", "Accuracy"]
log = pd.DataFrame(columns=log_cols)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)
acc_dict = {}

for clf in classifiers:
	name = clf.__class__.__name__
	clf.fit(X_train, y_train)
	train_predictions = clf.predict(X_test)
	acc = accuracy_score(y_test, train_predictions)
	if name in acc_dict:
		acc_dict[name] += acc
	else:
		acc_dict[name] = acc

for clf in acc_dict:
	acc_dict[clf] = acc_dict[clf] / 10.0
	log_entry = pd.DataFrame([[clf, acc_dict[clf]]], columns=log_cols)
	log = log.append(log_entry)

plt.xlabel('Accuracy')
plt.title('Classifier Accuracy')

sns.set_color_codes("muted")
sns.barplot(x='Accuracy', y='Classifier', data=log.sort_values(by='Accuracy'), color="b")

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score

classifiers = [
    KNeighborsClassifier(5),
    SVC(probability=True, kernel='rbf'),
    DecisionTreeClassifier(),
    RandomForestClassifier(),
    GaussianNB(),
    LogisticRegression(),
]

log_cols = ["Classifier", "f1"]
log = pd.DataFrame(columns=log_cols)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)
acc_dict = {}

for clf in classifiers:
	name = clf.__class__.__name__
	clf.fit(X_train, y_train)
	train_predictions = clf.predict(X_test)
	acc = f1_score(y_test, train_predictions)
	if name in acc_dict:
		acc_dict[name] += acc
	else:
		acc_dict[name] = acc

for clf in acc_dict:
	acc_dict[clf] = acc_dict[clf] / 10.0
	log_entry = pd.DataFrame([[clf, acc_dict[clf]]], columns=log_cols)
	log = log.append(log_entry)

plt.xlabel('f1')
plt.title('Classifier f1')

sns.set_color_codes("muted")
sns.barplot(x='f1', y='Classifier', data=log.sort_values(by='f1'), color="b")

